{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4846110",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths configuration\n",
    "EMBEDDING_DIR_PATH = \"\"  # Path to the directory containing embedding files\n",
    "OUTPUT_DIR_PATH = \"\"  # Path to save retrieval results\n",
    "\n",
    "# Retrieval parameters\n",
    "TARGET_EMBEDDING_DIM = 128\n",
    "K_ANN_CANDIDATES = 100\n",
    "K_FINAL_RETRIEVAL = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1e47d",
   "metadata": {},
   "source": [
    "# Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd708d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def to_torch_tensor(data):\n",
    "    \"\"\"Convert numpy array or torch tensor to torch tensor.\"\"\"\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return torch.from_numpy(data)\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported data type: {type(data)}\")\n",
    "\n",
    "def process_embedding_for_ann(emb_raw, target_dim, name=\"embedding\"):\n",
    "    \"\"\"\n",
    "    Process an embedding for ANN indexing by standardizing to target dimension.\n",
    "    \n",
    "    Args:\n",
    "        emb_raw: Raw embedding tensor\n",
    "        target_dim: Target embedding dimension\n",
    "        name: Name for logging purposes\n",
    "    \n",
    "    Returns:\n",
    "        Processed single vector or None if invalid\n",
    "    \"\"\"\n",
    "    if emb_raw.numel() == 0:\n",
    "        print(f\"Warning: {name} has an empty embedding. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Remove singleton batch dimension\n",
    "    emb_processed = emb_raw.squeeze(0)\n",
    "    \n",
    "    if emb_processed.numel() == 0:\n",
    "        print(f\"Warning: {name} has an empty embedding after processing. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Check dimensions\n",
    "    is_2d_and_correct_dim = (emb_processed.dim() == 2 and emb_processed.shape[1] == target_dim)\n",
    "    is_1d_and_correct_dim = (emb_processed.dim() == 1 and emb_processed.shape[0] == target_dim)\n",
    "    \n",
    "    if not (is_2d_and_correct_dim or is_1d_and_correct_dim):\n",
    "        print(f\"Warning: {name} has unexpected embedding shape: {emb_processed.shape}. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to single vector\n",
    "    if emb_processed.dim() == 2:\n",
    "        single_vector = torch.mean(emb_processed, dim=0).to(torch.float32)\n",
    "    else:\n",
    "        single_vector = emb_processed.to(torch.float32)\n",
    "    \n",
    "    return single_vector\n",
    "\n",
    "def build_faiss_index(embeddings_list, target_dim):\n",
    "    \"\"\"\n",
    "    Build FAISS index from list of embeddings.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_list: List of raw embeddings\n",
    "        target_dim: Target embedding dimension\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (faiss_index, ann_vectors, valid_indices, embedding_map)\n",
    "    \"\"\"\n",
    "    processed_ann_vectors = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    print(f\"Standardizing embeddings to {target_dim} dimensions...\")\n",
    "    \n",
    "    for i, emb_raw in enumerate(tqdm(embeddings_list, desc=\"Processing for ANN\")):\n",
    "        single_vector = process_embedding_for_ann(emb_raw, target_dim, f\"embedding {i}\")\n",
    "        if single_vector is not None:\n",
    "            processed_ann_vectors.append(single_vector)\n",
    "            valid_indices.append(i)\n",
    "    \n",
    "    if not processed_ann_vectors:\n",
    "        raise ValueError(\"No valid ANN vectors could be generated.\")\n",
    "    \n",
    "    ann_vectors = torch.stack(processed_ann_vectors).cpu().numpy()\n",
    "    \n",
    "    # Store original embeddings for reranking\n",
    "    embedding_map = {}\n",
    "    for original_idx in valid_indices:\n",
    "        embedding_map[original_idx] = embeddings_list[original_idx]\n",
    "    \n",
    "    # Create FAISS index\n",
    "    d = ann_vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(ann_vectors)\n",
    "    print(f\"FAISS index created with {index.ntotal} vectors.\")\n",
    "    \n",
    "    return index, ann_vectors, valid_indices, embedding_map\n",
    "\n",
    "def perform_retrieval_with_reranking(query_embeddings, faiss_index, valid_indices, \n",
    "                                     embedding_map, metadata, processor, \n",
    "                                     k_candidates=100, k_final=100):\n",
    "    \"\"\"\n",
    "    Perform retrieval with FAISS + reranking.\n",
    "    \n",
    "    Args:\n",
    "        query_embeddings: List of query embeddings\n",
    "        faiss_index: FAISS index for ANN search\n",
    "        valid_indices: Valid indices mapping\n",
    "        embedding_map: Map of original embeddings\n",
    "        metadata: Metadata for candidates\n",
    "        processor: Model processor for scoring\n",
    "        k_candidates: Number of candidates from ANN\n",
    "        k_final: Number of final results\n",
    "    \n",
    "    Returns:\n",
    "        List of search results\n",
    "    \"\"\"\n",
    "    all_search_results = []\n",
    "    \n",
    "    # Process queries for ANN\n",
    "    processed_query_vectors = []\n",
    "    for q_emb_raw in tqdm(query_embeddings, desc=\"Processing queries for ANN\"):\n",
    "        single_vector = process_embedding_for_ann(q_emb_raw, TARGET_EMBEDDING_DIM, \"query\")\n",
    "        if single_vector is None:\n",
    "            single_vector = torch.zeros(TARGET_EMBEDDING_DIM, dtype=torch.float32)\n",
    "        processed_query_vectors.append(single_vector)\n",
    "    \n",
    "    if not processed_query_vectors:\n",
    "        raise ValueError(\"No valid query vectors could be generated.\")\n",
    "    \n",
    "    query_ann_vectors = torch.stack(processed_query_vectors).cpu().numpy()\n",
    "    \n",
    "    print(f\"Total queries to process: {len(query_embeddings)}\")\n",
    "    \n",
    "    for i in tqdm(range(len(query_embeddings)), desc=\"Retrieving and Reranking\"):\n",
    "        query_original_emb = query_embeddings[i]\n",
    "        query_ann_vec = query_ann_vectors[i:i+1]\n",
    "        \n",
    "        # FAISS search\n",
    "        D, I = faiss_index.search(query_ann_vec, k_candidates)\n",
    "        faiss_candidate_indices = I[0]\n",
    "        \n",
    "        # Reranking\n",
    "        reranked_scores = []\n",
    "        for faiss_idx in faiss_candidate_indices:\n",
    "            if faiss_idx == -1:\n",
    "                continue\n",
    "            \n",
    "            original_idx = valid_indices[faiss_idx]\n",
    "            candidate_original_emb = embedding_map[original_idx]\n",
    "            \n",
    "            # Get metadata for this candidate\n",
    "            candidate_meta = metadata[original_idx]\n",
    "            \n",
    "            # Calculate similarity score\n",
    "            score = processor.score_multi_vector(query_original_emb, candidate_original_emb)\n",
    "            reranked_scores.append((score.item(), original_idx, candidate_meta))\n",
    "        \n",
    "        # Sort by score (descending) and take top K\n",
    "        reranked_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Store results\n",
    "        for rank, (score, result_idx, candidate_meta) in enumerate(reranked_scores[:k_final]):\n",
    "            result = {\n",
    "                'query_id': i,\n",
    "                'result_rank': rank + 1,\n",
    "                'result_id': result_idx,\n",
    "                'score': float(f\"{score:.4f}\")\n",
    "            }\n",
    "            result.update(candidate_meta)\n",
    "            all_search_results.append(result)\n",
    "    \n",
    "    return all_search_results\n",
    "\n",
    "print(\"Helper functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6e405",
   "metadata": {},
   "source": [
    "# Retrieval with ColQwen2.5 (Image to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a6c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colpali_engine.models import ColQwen2_5, ColQwen2_5_Processor\n",
    "\n",
    "# Load model and processor\n",
    "model_name = \"Metric-AI/ColQwen2.5-7b-multilingual-v1.0\"\n",
    "model_name_only = model_name.split(\"/\")[-1]\n",
    "processor = ColQwen2_5_Processor.from_pretrained(model_name)\n",
    "\n",
    "# Load embeddings\n",
    "file_name = \"image_text_embeddings_ColQwen2.5-3b-multilingual-v1.0_0_3600.pkl\"\n",
    "with open(os.path.join(EMBEDDING_DIR_PATH, file_name), 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Extract caption embeddings from all languages as candidates\n",
    "all_caption_embeddings = []\n",
    "caption_metadata = []\n",
    "\n",
    "print(\"Extracting caption embeddings from all languages...\")\n",
    "for entry_idx, entry in enumerate(tqdm(embeddings, desc=\"Processing entries\")):\n",
    "    if 'text_embeddings' in entry:\n",
    "        for lang_key, lang_embeddings in entry['text_embeddings'].items():\n",
    "            # Extract language code from key (e.g., 'caption_embedding_en' -> 'en')\n",
    "            lang_code = lang_key.replace('caption_embedding_', '')\n",
    "            \n",
    "            for caption_idx, caption_emb in enumerate(lang_embeddings):\n",
    "                all_caption_embeddings.append(to_torch_tensor(caption_emb))\n",
    "                caption_metadata.append({\n",
    "                    'entry_idx': entry_idx,\n",
    "                    'language': lang_code,\n",
    "                    'caption_idx': caption_idx,\n",
    "                    'image_key': entry.get('image_key', f'entry_{entry_idx}')\n",
    "                })\n",
    "\n",
    "# Extract image embeddings for queries\n",
    "all_query_embeddings = []\n",
    "query_metadata = []\n",
    "\n",
    "print(\"Extracting image embeddings for queries...\")\n",
    "for entry_idx, entry in enumerate(tqdm(embeddings, desc=\"Processing queries\")):\n",
    "    if 'image_embedding' in entry:\n",
    "        all_query_embeddings.append(to_torch_tensor(entry['image_embedding']))\n",
    "        query_metadata.append({\n",
    "            'entry_idx': entry_idx,\n",
    "            'image_key': entry.get('image_key', f'entry_{entry_idx}')\n",
    "        })\n",
    "\n",
    "# Build FAISS index for captions\n",
    "faiss_index, _, valid_caption_indices, caption_embedding_map = build_faiss_index(\n",
    "    all_caption_embeddings, TARGET_EMBEDDING_DIM\n",
    ")\n",
    "\n",
    "# Perform retrieval with reranking\n",
    "all_search_results = perform_retrieval_with_reranking(\n",
    "    all_query_embeddings, \n",
    "    faiss_index, \n",
    "    valid_caption_indices, \n",
    "    caption_embedding_map, \n",
    "    caption_metadata, \n",
    "    processor,\n",
    "    k_candidates=K_ANN_CANDIDATES,\n",
    "    k_final=K_FINAL_RETRIEVAL\n",
    ")\n",
    "\n",
    "# Add query metadata to results\n",
    "for result in all_search_results:\n",
    "    query_id = result['query_id']\n",
    "    result['query_image_key'] = query_metadata[query_id]['image_key']\n",
    "    result['result_image_key'] = result.pop('image_key')\n",
    "\n",
    "# Save results\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)\n",
    "df = pd.DataFrame(all_search_results)\n",
    "output_file = os.path.join(OUTPUT_DIR_PATH, f'{file_name}_multilingual_results.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to: {output_file}\")\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Language distribution:\")\n",
    "print(df['language'].value_counts())\n",
    "print(f\"Sample results:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057eeb0",
   "metadata": {},
   "source": [
    "# Retrieval with ColQwen2 (Image to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d352c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colpali_engine.models import ColQwen2, ColQwen2Processor\n",
    "\n",
    "# Load model and processor\n",
    "model_name = \"vidore/colqwen2-v1.0\"\n",
    "model_name_only = model_name.split(\"/\")[-1]\n",
    "processor = ColQwen2Processor.from_pretrained(model_name)\n",
    "\n",
    "# Load embeddings\n",
    "file_name = \"image_text_embeddings_colqwen2-v1.0_0_3600.pkl\"\n",
    "with open(os.path.join(EMBEDDING_DIR_PATH, file_name), 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Extract embeddings from schema\n",
    "all_candidate_embeddings = []\n",
    "candidate_metadata = []\n",
    "all_query_embeddings = []\n",
    "query_metadata = []\n",
    "\n",
    "print(\"Extracting embeddings from schema...\")\n",
    "for entry_idx, entry in enumerate(tqdm(embeddings, desc=\"Processing entries\")):\n",
    "    # Extract image embedding (used as query)\n",
    "    if 'image_embedding' in entry:\n",
    "        image_emb = to_torch_tensor(entry['image_embedding'])\n",
    "        all_query_embeddings.append(image_emb)\n",
    "        query_metadata.append({\n",
    "            'entry_idx': entry_idx,\n",
    "            'image_key': entry.get('image_key', f'entry_{entry_idx}')\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Warning: No image_embedding found in entry {entry_idx}\")\n",
    "        continue\n",
    "    \n",
    "    # Extract text embeddings from all languages (used as candidates)\n",
    "    if 'text_embeddings' in entry:\n",
    "        for lang_key, lang_embeddings_list in entry['text_embeddings'].items():\n",
    "            lang_code = lang_key.replace('caption_embedding_', '')\n",
    "            for caption_idx, caption_emb_array in enumerate(lang_embeddings_list):\n",
    "                caption_emb = to_torch_tensor(caption_emb_array)\n",
    "                all_candidate_embeddings.append(caption_emb)\n",
    "                candidate_metadata.append({\n",
    "                    'entry_idx': entry_idx,\n",
    "                    'type': 'caption',\n",
    "                    'language': lang_code,\n",
    "                    'caption_idx': caption_idx,\n",
    "                    'image_key': entry.get('image_key', f'entry_{entry_idx}')\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Warning: No text_embeddings found in entry {entry_idx}\")\n",
    "\n",
    "print(f\"Total candidate embeddings: {len(all_candidate_embeddings)}\")\n",
    "print(f\"Total query embeddings: {len(all_query_embeddings)}\")\n",
    "\n",
    "# Build FAISS index for candidates\n",
    "faiss_index, _, valid_indices, embedding_map = build_faiss_index(\n",
    "    all_candidate_embeddings, TARGET_EMBEDDING_DIM\n",
    ")\n",
    "\n",
    "# Perform retrieval with reranking\n",
    "all_search_results = perform_retrieval_with_reranking(\n",
    "    all_query_embeddings,\n",
    "    faiss_index,\n",
    "    valid_indices,\n",
    "    embedding_map,\n",
    "    candidate_metadata,\n",
    "    processor,\n",
    "    k_candidates=K_ANN_CANDIDATES,\n",
    "    k_final=K_FINAL_RETRIEVAL\n",
    ")\n",
    "\n",
    "# Add query metadata to results\n",
    "for result in all_search_results:\n",
    "    query_id = result['query_id']\n",
    "    result['query_image_key'] = query_metadata[query_id]['image_key']\n",
    "\n",
    "# Save results\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)\n",
    "df = pd.DataFrame(all_search_results)\n",
    "output_file = os.path.join(OUTPUT_DIR_PATH, f'{file_name}_results.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to: {output_file}\")\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Candidate types distribution:\")\n",
    "print(df['type'].value_counts())\n",
    "if 'language' in df.columns:\n",
    "    print(f\"Language distribution:\")\n",
    "    print(df['language'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
